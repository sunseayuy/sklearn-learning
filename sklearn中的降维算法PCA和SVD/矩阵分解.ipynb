{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''降维算法中的”降维“，指的是降低特征矩阵中特征的数量。上周的课中我们说过，降维的目的是为了让算法运算更\n",
    "快，效果更好，但其实还有另一种需求：数据可视化。从上面的图我们其实可以看得出，图像和特征矩阵的维度是\n",
    "可以相互对应的，即一个特征对应一个特征向量，对应一条坐标轴。所以，三维及以下的特征矩阵，是可以被可视\n",
    "化的，这可以帮助我们很快地理解数据的分布，而三维以上特征矩阵的则不能被可视化，数据的性质也就比较难理\n",
    "解。'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn中降维算法都被包括在模块decomposition中，这个模块本质是一个矩阵分解模块。\n",
    "\n",
    "#PCA使用的信息量衡量指标，就是样本方差，又称可解释性方差，方差越大，特征所带的信息量越多。\n",
    "\n",
    "#class sklearn.decomposition.PCA (n_components=None, copy=True, whiten=False, svd_solver=’auto’, tol=0.0,iterated_power=’auto’, random_state=None)\n",
    "#通过某种变化，找出n个新的特征向量，以及它们构成的新n维空间V\n",
    "#找出原始数据在新特征空间V中的n个新特征向量上对应的值，即“将数据映射到新空间中”\n",
    "#找出n个新特征向量，让数据能够被压缩到少数特征上并且总信息量不损失太多的技术就是矩阵分解。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
