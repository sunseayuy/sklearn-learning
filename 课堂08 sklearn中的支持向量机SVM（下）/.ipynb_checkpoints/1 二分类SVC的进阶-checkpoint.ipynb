{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2 参数C的理解进阶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_circles, make_moons, make_blobs,make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "datasets = [\n",
    "    make_moons(n_samples=n_samples, noise=0.2, random_state=0),\n",
    "    make_circles(n_samples=n_samples, noise=0.2, factor=0.5, random_state=1),\n",
    "    make_blobs(n_samples=n_samples, centers=2, random_state=5),\n",
    "    make_classification(n_samples=n_samples,n_features = 2,n_informative=2,n_redundant=0, random_state=5)]\n",
    "Kernel = [\"linear\"] #四个数据集分别是什么样子呢？\n",
    "for X,Y in datasets:\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.scatter(X[:,0],X[:,1],c=Y,s=50,cmap=\"rainbow\")\n",
    "nrows=len(datasets)\n",
    "ncols=len(Kernel) + 1\n",
    "fig, axes = plt.subplots(nrows, ncols,figsize=(10,16))\n",
    "#第一层循环：在不同的数据集中循环\n",
    "for ds_cnt, (X,Y) in enumerate(datasets):\n",
    "    ax = axes[ds_cnt, 0]\n",
    "    if ds_cnt == 0:\n",
    "        ax.set_title(\"Input data\")\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=Y, zorder=10, cmap=plt.cm.Paired,edgecolors='k')\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    \n",
    "    for est_idx, kernel in enumerate(Kernel):\n",
    "        ax = axes[ds_cnt, est_idx + 1]\n",
    "\n",
    "        clf = svm.SVC(kernel=kernel, gamma=2).fit(X, Y)\n",
    "        score = clf.score(X, Y)\n",
    "\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=Y\n",
    "                    ,zorder=10\n",
    "                    ,cmap=plt.cm.Paired,edgecolors='k')\n",
    "        ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=100,\n",
    "                    facecolors='none', zorder=10, edgecolors='white')\n",
    "\n",
    "        x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "        y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "\n",
    "        XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "        Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()]).reshape(XX.shape)\n",
    "        ax.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)\n",
    "        ax.contour(XX, YY, Z, colors=['k', 'k', 'k'], linestyles=['--', '-', '--'],\n",
    "        levels=[-1, 0, 1])\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "\n",
    "        if ds_cnt == 0:\n",
    "            ax.set_title(kernel)\n",
    "\n",
    "        ax.text(0.95, 0.06, ('%.2f' % score).lstrip('0')\n",
    "                , size=15\n",
    "                , bbox=dict(boxstyle='round', alpha=0.8, facecolor='white')\n",
    "                #为分数添加一个白色的格子作为底色\n",
    "                , transform=ax.transAxes #确定文字所对应的坐标轴，就是ax子图的坐标轴本身\n",
    "                , horizontalalignment='right' #位于坐标轴的什么方向\n",
    "                )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.3 二分类SVC中的样本不均衡问题：重要参数class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. 导入需要的库和模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. 创建样本不均衡的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_1 = 500 #类别1有500个样本\n",
    "class_2 = 50 #类别2只有50个\n",
    "centers = [[0.0, 0.0], [2.0, 2.0]] #设定两个类别的中心\n",
    "clusters_std = [1.5, 0.5] #设定两个类别的方差，通常来说，样本量比较大的类别会更加松散\n",
    "X, y = make_blobs(n_samples=[class_1, class_2],\n",
    "                 centers=centers,\n",
    "                 cluster_std=clusters_std,\n",
    "                 random_state=0, shuffle=False) \n",
    "#看看数据集长什么样\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=\"rainbow\",s=10) \n",
    "#其中红色点是少数类，紫色点是多数类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 在数据集上分别建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#不设定class_weight\n",
    "clf = svm.SVC(kernel='linear', C=1.0)\n",
    "clf.fit(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设定class_weight\n",
    "wclf = svm.SVC(kernel='linear', class_weight={1: 10})\n",
    "wclf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#给两个模型分别打分看看，这个分数是accuracy准确度\n",
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wclf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. 绘制两个模型下数据的决策边界"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#首先要有数据分布\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=\"rainbow\",s=10)\n",
    "ax = plt.gca()\n",
    "#获取当前的子图，如果不存在，则创建新的子图\n",
    "\n",
    "#绘制决策边界的第一步：要有网格\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T \n",
    "\n",
    "#第二步：找出我们的样本点到决策边界的距离\n",
    "Z_clf = clf.decision_function(xy).reshape(XX.shape) \n",
    "a = ax.contour(XX, YY, Z_clf, colors='black', levels=[0], alpha=0.5, linestyles=['-'])\n",
    "Z_wclf = wclf.decision_function(xy).reshape(XX.shape) \n",
    "b = ax.contour(XX, YY, Z_wclf, colors='red', levels=[0], alpha=0.5, linestyles=['-'])\n",
    "\n",
    "#第三步：画图例\n",
    "plt.legend([a.collections[0], b.collections[0]], [\"non weighted\", \"weighted\"],loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.collections #调用这个等高线对象中画的所有线，返回一个惰性对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用[*]把它打开试试看\n",
    "[*a.collections] #返回了一个linecollection对象，其实就是我们等高线里所有的线的列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#现在我们只有一条线，所以我们可以使用索引0来锁定这个对象\n",
    "a.collections[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.legend([对象列表],[图例列表],loc)\n",
    "#只要对象列表和图例列表相对应，就可以显示出图例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 SVC的模型评估指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1 混淆矩阵（Confusion Matrix）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1.2 捕捉少数类的艺术：精确度，召回率和F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#所有判断正确并确实为1的样本 / 所有被判断为1的样本\n",
    "#对于没有class_weight，没有做样本平衡的灰色决策边界来说：\n",
    "(y[y == clf.predict(X)] == 1).sum()/(clf.predict(X) == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y == clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对于有class_weight，做了样本平衡的红色决策边界来说：\n",
    "(y[y == wclf.predict(X)] == 1).sum()/(wclf.predict(X) == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#所有predict为1的点 / 全部为1的点的比例\n",
    "#对于没有class_weight，没有做样本平衡的灰色决策边界来说：\n",
    "(y[y == clf.predict(X)] == 1).sum()/(y == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对于有class_weight，做了样本平衡的红色决策边界来说：\n",
    "(y[y == wclf.predict(X)] == 1).sum()/(y == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1.3 判错多数类的考量：特异度与假正率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#所有被正确预测为0的样本 / 所有的0样本\n",
    "#对于没有class_weight，没有做样本平衡的灰色决策边界来说：\n",
    "(y[y == clf.predict(X)] == 0).sum()/(y == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对于有class_weight，做了样本平衡的红色决策边界来说：\n",
    "(y[y == wclf.predict(X)] == 0).sum()/(y == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2.1 概率(probability)与阈值(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. 自建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_1_ = 7\n",
    "class_2_ = 4\n",
    "centers_ = [[0.0, 0.0], [1,1]]\n",
    "clusters_std = [0.5, 1]\n",
    "X_, y_ = make_blobs(n_samples=[class_1_, class_2_],\n",
    "                    centers=centers_,\n",
    "                    cluster_std=clusters_std,\n",
    "                    random_state=0, shuffle=False)\n",
    "plt.scatter(X_[:, 0], X_[:, 1], c=y_, cmap=\"rainbow\",s=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. 建模，调用概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LogiR\n",
    "clf_lo = LogiR().fit(X_,y_)\n",
    "prob = clf_lo.predict_proba(X_) \n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将样本和概率放到一个DataFrame中\n",
    "import pandas as pd\n",
    "prob = pd.DataFrame(prob)\n",
    "prob.columns = [\"0\",\"1\"]\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 使用阈值0.5，大于0.5的样本被预测为1，小于0.5的样本被预测为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#手动调节阈值，来改变我们的模型效果\n",
    "for i in range(prob.shape[0]):\n",
    "    if prob.loc[i,\"1\"] > 0.5:\n",
    "        prob.loc[i,\"pred\"] = 1\n",
    "    else:\n",
    "        prob.loc[i,\"pred\"] = 0\n",
    "prob[\"y_true\"] = y_\n",
    "prob = prob.sort_values(by=\"1\",ascending=False)\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. 使用混淆矩阵查看结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix as CM, precision_score as P, recall_score as R\n",
    "CM(prob.loc[:,\"y_true\"],prob.loc[:,\"pred\"],labels=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#试试看手动计算Precision和Recall?\n",
    "P(prob.loc[:,\"y_true\"],prob.loc[:,\"pred\"],labels=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R(prob.loc[:,\"y_true\"],prob.loc[:,\"pred\"],labels=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. 假如我们使用0.4作为阈值呢？\n",
    "for i in range(prob.shape[0]):\n",
    "    if prob.loc[i,\"1\"] > 0.4:\n",
    "        prob.loc[i,\"pred\"] = 1\n",
    "    else:\n",
    "        prob.loc[i,\"pred\"] = 0\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM(prob.loc[:,\"y_true\"],prob.loc[:,\"pred\"],labels=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P(prob.loc[:,\"y_true\"],prob.loc[:,\"pred\"],labels=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R(prob.loc[:,\"y_true\"],prob.loc[:,\"pred\"],labels=[1,0])\n",
    "#注意，降低或者升高阈值并不一定能够让模型的效果变好，一切都基于我们要追求怎样的模型效果\n",
    "#通常来说降低阈值可以降低recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2.2 SVM实现概率预测：重要参数probability，接口predict_proba以及decision_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用最初的X和y，样本不均衡的这个模型\n",
    "class_1 = 500 #类别1有500个样本\n",
    "class_2 = 50 #类别2只有50个\n",
    "centers = [[0.0, 0.0], [2.0, 2.0]] #设定两个类别的中心\n",
    "clusters_std = [1.5, 0.5] #设定两个类别的方差，通常来说，样本量比较大的类别会更加松散\n",
    "X, y = make_blobs(n_samples=[class_1, class_2],\n",
    "                  centers=centers,\n",
    "                  cluster_std=clusters_std,\n",
    "                  random_state=0, shuffle=False) #看看数据集长什么样\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=\"rainbow\",s=10) #其中红色点是少数类，紫色点是多数类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_proba = svm.SVC(kernel=\"linear\",C=1.0,probability=True).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_proba.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_proba.predict_proba(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_proba.decision_function(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_proba.decision_function(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.2.3 绘制SVM的ROC曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#首先来看看如何从混淆矩阵中获取FPR和Recall\n",
    "cm = CM(prob.loc[:,\"y_true\"],prob.loc[:,\"pred\"],labels=[1,0])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FPR\n",
    "cm[1,0]/cm[1,:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recall\n",
    "cm[0,0]/cm[0,:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.概率 clf_proba.predict_proba(X)[:,1] #我的类别1下得概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#开始绘图\n",
    "recall = []\n",
    "FPR = []\n",
    "probrange = np.linspace(clf_proba.predict_proba(X)[:,1].min(),clf_proba.predict_proba(X)[:,1].max(),num=50,endpoint=False)\n",
    "from sklearn.metrics import confusion_matrix as CM, recall_score as R\n",
    "import matplotlib.pyplot as plot\n",
    "for i in probrange:\n",
    "    y_predict = []\n",
    "    for j in range(X.shape[0]):\n",
    "        if clf_proba.predict_proba(X)[j,1] > i:\n",
    "            y_predict.append(1)\n",
    "        else:\n",
    "            y_predict.append(0)\n",
    "    cm = CM(y,y_predict,labels=[1,0])\n",
    "    recall.append(cm[0,0]/cm[0,:].sum())\n",
    "    FPR.append(cm[1,0]/cm[1,:].sum())\n",
    "recall.sort()\n",
    "FPR.sort()\n",
    "plt.plot(FPR,recall,c=\"red\")\n",
    "plt.plot(probrange+0.05,probrange+0.05,c=\"black\",linestyle=\"--\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
